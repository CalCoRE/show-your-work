{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üçé Analyzing **Linear Relationships** in Science with Computational Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59af770",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ PURPOSE: Why Use Computational Notebooks for Data Analysis?\n",
    "\n",
    "Computational notebooks, like **Jupyter Notebooks**, offer a unique blend of **narrative text**, **executable code**, and **visualizations** all in one place. For analyzing experimental science data, this is incredibly powerful:\n",
    "\n",
    "* **Reproducibility:** A notebook captures the entire analysis process‚Äîthe data, the cleaning steps, the calculations (like linear regression), and the final graph. Anyone can re-run the exact analysis and get the same results. In science, this is crucial for verifying findings.\n",
    "\n",
    "* **Live Documentation:** Unlike static lab reports or spreadsheets, the code itself is right next to the explanation. You can explain *why* you are performing a linear regression and then execute the regression in the next cell. This makes the **methodology transparent**.\n",
    "\n",
    "* **Iterative Exploration:** It's easy to change a single line of code (e.g., to exclude an outlier, switch the regression type) and immediately see the effect on the graph and results. This encourages **scientific curiosity and testing hypotheses**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144ad584",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚öñÔ∏è COMPARISON: Notebooks vs. Spreadsheets\n",
    "\n",
    "| Feature | Computational Notebooks (e.g., Jupyter) | Spreadsheet Software (e.g., Excel, Sheets) |\n",
    "| :--- | :--- | :--- |\n",
    "| **Methodology** | **Transparent:** Code explicitly defines every step (cleaning, calculation, plotting). | **Opaque:** Steps are often hidden in cell formulas or menus; harder to see the full process. |\n",
    "| **Documentation** | **Integrated:** Text/Explanations surround the live code and outputs. | **Separate:** Explanations are usually added in a separate document. |\n",
    "| **Advanced Analysis** | **Powerful:** Easily handles complex tasks like error analysis, simulation, and advanced statistics. | **Limited:** Often requires add-ons or complex functions for advanced statistical modeling. |\n",
    "| **Pedagogical Benefit** | Great for teaching **computational thinking** and **data literacy**; learners see the *how* and *why*. | Great for data entry and simple calculations; can quickly create basic graphs. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fc109a",
   "metadata": {},
   "source": [
    "---\n",
    "## üß™ CONTENT: Exploring **Newton's Second Law**\n",
    "\n",
    "Today, we are analyzing data from a classic high school physics experiment: pulling a cart on a horizontal plane. The goal is to verify **Newton's Second Law** of Motion:\n",
    "\n",
    "$$\\mathbf{F}_{net} = m \\cdot \\mathbf{a}$$\n",
    "\n",
    "Where:\n",
    "* $\\mathbf{F}_{net}$ is the **Net Force** (Newtons, N) applied to the system.\n",
    "* $m$ is the **Mass** (kilograms, kg) of the system (cart + weights).\n",
    "* $\\mathbf{a}$ is the **Acceleration** ($m/s^2$) of the system.\n",
    "\n",
    "### The Effect of Friction\n",
    "\n",
    "In a real-world experiment, there is always a resistive force, **friction** ($\\mathbf{F}_{friction}$), that opposes the motion. This force must be overcome before the cart can accelerate. The actual equation governing the experiment is:\n",
    "\n",
    "$$\\mathbf{F}_{applied} = m \\cdot \\mathbf{a} + \\mathbf{F}_{friction}$$\n",
    "\n",
    "When we plot **Applied Force** ($\\mathbf{F}$) on the y-axis against **Acceleration** ($\\mathbf{a}$) on the x-axis, we expect a **linear relationship** ($y = mx + b$):\n",
    "\n",
    "* **Slope ($m$):** Represents the **Mass** of the system.\n",
    "* **Y-Intercept ($b$):** Represents the force needed to overcome the **Friction**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b68fd3e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üìä PART 1: Using Linear Regression to Verify F=ma\n",
    "\n",
    "## Learning Goal: Understand and apply linear regression\n",
    "\n",
    "In this first part, we'll learn how to use **linear regression** to analyze experimental data and verify Newton's Second Law. We'll work with all our data points to understand the fundamentals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee297a3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üß± CODE BLOCK 1: Loading and Inspecting the Data\n",
    "\n",
    "Before we start, we need to load our experimental data. This data was collected by measuring the acceleration of a cart system when different pulling forces were applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66d137a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Code in this cell sets up the environment and loads the data for analysis.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# We will use two core tools: one for data handling and one for plotting.\u001b[39;00m\n\u001b[32m      3\u001b[39m \n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# [Language-A: Python]\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m \u001b[38;5;66;03m# Tool for data manipulation and analysis\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m \u001b[38;5;66;03m# Tool for numerical operations, like calculating the line of best fit\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m \u001b[38;5;66;03m# Tool for creating static, interactive, and animated visualizations\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Code in this cell sets up the environment and loads the data for analysis.\n",
    "# We will use two core tools: one for data handling and one for plotting.\n",
    "\n",
    "# [Language-A: Python]\n",
    "import pandas as pd # Tool for data manipulation and analysis\n",
    "import numpy as np # Tool for numerical operations, like calculating the line of best fit\n",
    "import matplotlib.pyplot as plt # Tool for creating static, interactive, and animated visualizations\n",
    "from scipy.stats import linregress # Specific tool for linear regression\n",
    "\n",
    "# [Language-B: R]\n",
    "# library(tidyverse) # Collection of R packages designed for data science\n",
    "# library(mosaic) # Helpful package for statistics and data manipulation\n",
    "\n",
    "# Experimental data: [Acceleration (a) in m/s^2, Applied Force (F) in N]\n",
    "data = {\n",
    "    'Acceleration': [0.00, 0.15, 0.23, 0.31, 0.45, 0.52, 0.59, 0.76, 0.90, 0.98, 1.05, 1.20, 1.40, 1.55, 1.70],\n",
    "    'Force': [0.60, 0.48, 0.54, 0.60, 0.72, 0.78, 0.85, 0.98, 1.40, 1.18, 1.25, 1.37, 1.50, 1.63, 1.76]\n",
    "}# Note: The first point (0.00, 0.35) shows that 0.35 N of force was needed to overcome friction and cause *some* motion, but the measured acceleration was negligible (approx. 0.00).\n",
    "\n",
    "# Create a data structure (often called a 'DataFrame') to hold the data\n",
    "# [Language-A: Python]\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# [Language-B: R]\n",
    "# df <- data.frame(data)\n",
    "\n",
    "# Display the first few rows to confirm the data loaded correctly.\n",
    "# [Language-A: Python]\n",
    "print(df.head())\n",
    "\n",
    "# [Language-B: R]\n",
    "# head(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679afe98",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìã Theoretical (Accepted) Values\n",
    "\n",
    "Before we analyze our experimental data, let's note the **theoretical (accepted) values** for comparison:\n",
    "\n",
    "* **Theoretical Mass** ($m_{accepted}$): **0.850 kg**\n",
    "  - This is the known mass of the cart system (cart + weights)\n",
    "\n",
    "* **Expected Kinetic Friction** ($F_{expected}$): **0.350 N**\n",
    "  - This is a reasonable estimate for the kinetic friction force\n",
    "  - Kinetic friction is typically lower than static friction\n",
    "\n",
    "**Goal:** Use linear regression to find the **experimental** values of mass and friction, then compare them to these accepted values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c835ae25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store theoretical (accepted) values for later comparison\n",
    "m_accepted = 0.850  # kg - Known mass of the cart system\n",
    "F_expected = 0.350  # N - Expected kinetic friction force\n",
    "\n",
    "print('=' * 60)\n",
    "print('THEORETICAL (ACCEPTED) VALUES')\n",
    "print('=' * 60)\n",
    "print(f'Theoretical Mass: {m_accepted:.3f} kg')\n",
    "print(f'Expected Kinetic Friction: {F_expected:.3f} N')\n",
    "print('\\nWe will compare our experimental results to these values.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d78c299",
   "metadata": {},
   "source": [
    "**Note:** We've loaded all our experimental data. Notice there are data points including one at acceleration = 0 (static friction) and some that might be outliers. We'll work with all of them in Part 1 to understand linear regression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b179f8dd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìà Step 1: Visualize the Data\n",
    "\n",
    "Let's start by creating a scatter plot of all our data points. This helps us see the overall relationship between Force and Acceleration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "251af396",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Code to create a scatter plot of Force vs. Acceleration for ALL data.\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Create the plot\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# [Language-A: Python]\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mplt\u001b[49m.figure(figsize=(\u001b[32m8\u001b[39m, \u001b[32m5\u001b[39m)) \u001b[38;5;66;03m# Sets the size of the visualization\u001b[39;00m\n\u001b[32m      6\u001b[39m plt.scatter(df[\u001b[33m'\u001b[39m\u001b[33mAcceleration\u001b[39m\u001b[33m'\u001b[39m], df[\u001b[33m'\u001b[39m\u001b[33mForce\u001b[39m\u001b[33m'\u001b[39m], color=\u001b[33m'\u001b[39m\u001b[33mdarkblue\u001b[39m\u001b[33m'\u001b[39m, s=\u001b[32m100\u001b[39m, label=\u001b[33m'\u001b[39m\u001b[33mAll Experimental Data\u001b[39m\u001b[33m'\u001b[39m, alpha=\u001b[32m0.7\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# [Language-B: R]\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# ggplot(df, aes(x=Acceleration, y=Force)) + geom_point(color='darkblue', size=3) +\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# labs(title='Force vs. Acceleration: All Data', x='Acceleration (a in m/s¬≤)', y='Force (F in N)') + theme_minimal()\u001b[39;00m\n\u001b[32m     11\u001b[39m \n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Add helpful labels and a title\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Code to create a scatter plot of Force vs. Acceleration for ALL data.\n",
    "\n",
    "# Create the plot\n",
    "# [Language-A: Python]\n",
    "plt.figure(figsize=(8, 5)) # Sets the size of the visualization\n",
    "plt.scatter(df['Acceleration'], df['Force'], color='darkblue', s=100, label='All Experimental Data', alpha=0.7)\n",
    "\n",
    "# [Language-B: R]\n",
    "# ggplot(df, aes(x=Acceleration, y=Force)) + geom_point(color='darkblue', size=3) +\n",
    "# labs(title='Force vs. Acceleration: All Data', x='Acceleration (a in m/s¬≤)', y='Force (F in N)') + theme_minimal()\n",
    "\n",
    "# Add helpful labels and a title\n",
    "plt.title('Force vs. Acceleration: All Data Points', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Acceleration (a in $m/s^2$)', fontsize=12)\n",
    "plt.ylabel('Applied Force (F in N)', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print('\\nObservation: We can see all data points. Notice the point at a=0 (static friction) and potential outliers in the middle range.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f150b7a7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Understanding Linear Regression: Finding the \"Best Fit\" Line\n",
    "\n",
    "Before we run our first regression, let's understand what **linear regression** actually does.\n",
    "\n",
    "### What is Linear Regression?\n",
    "\n",
    "**Linear regression** is a statistical method that finds the **\"line of best fit\"** through a set of data points. Imagine you have a scatter plot of points, and you want to draw a straight line that comes as close as possible to all of them. Linear regression does this mathematically.\n",
    "\n",
    "### The Goal: Minimize Error\n",
    "\n",
    "The regression algorithm finds the line that **minimizes the total squared distance** between the line and all data points. Think of it like this:\n",
    "- For each data point, measure how far it is from the line (vertically)\n",
    "- Square that distance (to make all distances positive and emphasize larger errors)\n",
    "- Add up all these squared distances\n",
    "- The \"best fit\" line is the one that makes this total as small as possible\n",
    "\n",
    "### What We Get from Regression\n",
    "\n",
    "When we perform linear regression, we get:\n",
    "\n",
    "1. **Slope ($m$):** The steepness of the line. In our experiment, this represents the **mass** of the cart system.\n",
    "2. **Y-Intercept ($b$):** Where the line crosses the y-axis. In our experiment, this represents the **friction force**.\n",
    "3. **R-squared ($R^2$):** A measure of how well the line fits the data (we'll explain this in detail below).\n",
    "\n",
    "### The Equation\n",
    "\n",
    "The line of best fit follows the familiar equation: $y = mx + b$, where:\n",
    "- $y$ is the dependent variable (Force, in our case)\n",
    "- $x$ is the independent variable (Acceleration, in our case)\n",
    "- $m$ is the slope (Mass)\n",
    "- $b$ is the y-intercept (Friction)\n",
    "\n",
    "In our physics context, this becomes: $\\mathbf{F} = m \\cdot \\mathbf{a} + \\mathbf{F}_{friction}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1faeccce",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üî¨ Step 2: Run Linear Regression\n",
    "\n",
    "Now let's apply linear regression to find the line of best fit through our data points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70c80c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression on ALL data (including outliers) - This is our baseline\n",
    "# [Language-A: Python]\n",
    "X_all = df['Acceleration']\n",
    "Y_all = df['Force']\n",
    "\n",
    "# Perform linear regression on ALL data\n",
    "# The linregress function finds the line that minimizes the sum of squared distances\n",
    "slope_all, intercept_all, r_value_all, p_value_all, std_err_all = linregress(X_all, Y_all)\n",
    "r_squared_all = r_value_all**2  # R-squared is the square of the correlation coefficient\n",
    "\n",
    "# [Language-B: R]\n",
    "# model_all <- lm(Force ~ Acceleration, data=df)\n",
    "# slope_all <- coef(model_all)['Acceleration']\n",
    "# intercept_all <- coef(model_all)['(Intercept)']\n",
    "# r_squared_all <- summary(model_all)$r.squared\n",
    "# std_err_all <- summary(model_all)$coefficients['Acceleration', 'Std. Error']\n",
    "\n",
    "# Print baseline results\n",
    "print('=' * 60)\n",
    "print('=' * 60)\n",
    "print(f\"Mass (Slope): {slope_all:.3f} kg\")\n",
    "print(f\"Friction Force (Y-Intercept): {intercept_all:.3f} N\")\n",
    "print(f\"R-squared: {r_squared_all:.4f} ({r_squared_all*100:.1f}% of variation explained)\")\n",
    "print(f\"Standard Error of Mass: {std_err_all:.3f} kg\")\n",
    "print(f\"\\nEquation: F = {slope_all:.3f}a + {intercept_all:.3f}\")\n",
    "\n",
    "# Interpret R-squared\n",
    "print('\\n' + '-' * 60)\n",
    "print('INTERPRETING THE R-SQUARED VALUE:')\n",
    "print('-' * 60)\n",
    "if r_squared_all >= 0.95:\n",
    "    interpretation = \"Excellent fit! The line explains almost all the variation.\"\n",
    "elif r_squared_all >= 0.80:\n",
    "    interpretation = \"Good fit. The line explains most of the variation, but there's some scatter.\"\n",
    "elif r_squared_all >= 0.50:\n",
    "    interpretation = \"Moderate fit. The line explains about half the variation‚Äîsignificant scatter present.\"\n",
    "else:\n",
    "    interpretation = \"Poor fit. The line explains little of the variation‚Äîweak linear relationship.\"\n",
    "\n",
    "print(f\"R¬≤ = {r_squared_all:.4f} means: {interpretation}\")\n",
    "print(f\"      As we clean the data, we expect R¬≤ to improve (increase).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b808b8dd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Understanding R-squared ($R^2$): How Well Does Our Line Fit?\n",
    "\n",
    "After running the regression, you saw an **R-squared** value. Let's understand what this important statistic means.\n",
    "\n",
    "### What is R-squared?\n",
    "\n",
    "**R-squared** (also written as $R^2$ or \"R-squared\") is a number between 0 and 1 that tells us **what percentage of the variation in the data is explained by our linear model**.\n",
    "\n",
    "### Interpreting R-squared Values\n",
    "\n",
    "- **$R^2 = 1.0$ (or 100%):** Perfect fit! All data points lie exactly on the line. This is extremely rare in real experiments.\n",
    "- **$R^2 = 0.95$ (or 95%):** Excellent fit! The line explains 95% of the variation. Most data points are very close to the line.\n",
    "- **$R^2 = 0.80$ (or 80%):** Good fit. The line explains 80% of the variation. Some scatter, but a clear linear trend.\n",
    "- **$R^2 = 0.50$ (or 50%):** Moderate fit. The line explains only half the variation. There's significant scatter.\n",
    "- **$R^2 = 0.0$ (or 0%):** No linear relationship. The line doesn't explain any of the variation‚Äîthe data is completely random with respect to the line.\n",
    "\n",
    "### In Our Experiment\n",
    "\n",
    "For our Force vs. Acceleration data:\n",
    "- A high $R^2$ (close to 1.0) means the data follows Newton's Second Law very well‚Äîthe relationship is strongly linear.\n",
    "- A low $R^2$ (far from 1.0) suggests either:\n",
    "  - Experimental errors (outliers, measurement mistakes)\n",
    "  - The relationship isn't truly linear (maybe friction changes with speed)\n",
    "  - There are other forces we haven't accounted for\n",
    "\n",
    "### Why We Care About R¬≤\n",
    "\n",
    "As we clean our data (remove outliers), we expect $R^2$ to **increase**. This tells us that:\n",
    "1. Our cleaned data has a stronger linear relationship\n",
    "2. We've successfully removed problematic data points\n",
    "3. Our final model is more reliable\n",
    "\n",
    "**Watch the R¬≤ values as we progress:** Baseline ‚Üí No Static Friction ‚Üí Clean Data. You should see them improve!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5982cd9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìê Step 3: Interpret the Results\n",
    "\n",
    "Let's understand what our regression tells us:\n",
    "\n",
    "* **Slope** = **Mass** of the cart system\n",
    "* **Y-Intercept** = **Friction Force** needed to overcome resistance\n",
    "* **R¬≤** = How well our line fits the data (closer to 1.0 is better)\n",
    "\n",
    "Our equation: $\\mathbf{F} = m \\cdot \\mathbf{a} + \\mathbf{F}_{friction}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79de94e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Step 4: Visualize the Best Fit Line\n",
    "\n",
    "Let's plot our data points along with the regression line to see how well it fits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd49b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data and regression line\n",
    "# Use variables from previous regression\n",
    "X_all = df['Acceleration']\n",
    "Y_all = df['Force']\n",
    "\n",
    "# Calculate line of best fit\n",
    "Y_fit = slope_all * X_all + intercept_all\n",
    "\n",
    "# Create plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(X_all, Y_all, color='darkblue', s=100, alpha=0.7, label='Experimental Data', zorder=2)\n",
    "plt.plot(X_all, Y_fit, color='red', linestyle='-', linewidth=2, label='Line of Best Fit', zorder=1)\n",
    "\n",
    "plt.title('Force vs. Acceleration with Linear Regression', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Acceleration (a in $m/s^2$)', fontsize=12)\n",
    "plt.ylabel('Applied Force (F in N)', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend()\n",
    "plt.annotate(f'F = {slope_all:.3f}a + {intercept_all:.3f}\\nR¬≤ = {r_squared_all:.4f}', \n",
    "             xy=(0.05, 0.95), xycoords='axes fraction', fontsize=10, \n",
    "             bbox=dict(boxstyle=\"round,pad=0.5\", fc=\"yellow\", alpha=0.5))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nSummary:')\n",
    "print(f'  ‚Ä¢ Mass (from slope): {slope_all:.3f} kg')\n",
    "print(f'  ‚Ä¢ Friction Force (from intercept): {intercept_all:.3f} N')\n",
    "print(f'  ‚Ä¢ R¬≤ = {r_squared_all:.4f} ({r_squared_all*100:.1f}% of variation explained)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be6da66",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîç Comparing Our Results to Theoretical Values\n",
    "\n",
    "Now let's compare our experimental results from Part 1 to the theoretical (accepted) values we defined earlier.\n",
    "\n",
    "**Percent Error** tells us how far off our experimental value is from the accepted value:\n",
    "\n",
    "$$\\text{Percent Error} = \\left| \\frac{\\text{Experimental Value} - \\text{Accepted Value}}{\\text{Accepted Value}} \\right| \\times 100\\%$$\n",
    "\n",
    "A smaller percent error means our experimental result is closer to the theoretical value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00dac63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Part 1 experimental results to theoretical values\n",
    "# Use the theoretical values defined earlier: m_accepted and F_expected\n",
    "\n",
    "# Experimental values from Part 1 regression\n",
    "experimental_mass_part1 = slope_all  # Mass from slope\n",
    "experimental_friction_part1 = intercept_all  # Friction from intercept\n",
    "\n",
    "# Calculate percent errors\n",
    "mass_error_part1 = abs((experimental_mass_part1 - m_accepted) / m_accepted) * 100\n",
    "friction_error_part1 = abs((experimental_friction_part1 - F_expected) / F_expected) * 100\n",
    "\n",
    "# Print comparison\n",
    "print('=' * 60)\n",
    "print('PART 1: EXPERIMENTAL vs THEORETICAL VALUES')\n",
    "print('=' * 60)\n",
    "print(f\"\\n{'Quantity':<25} {'Theoretical':<15} {'Experimental':<15} {'Percent Error'}\")\n",
    "print('-' * 60)\n",
    "print(f\"{'Mass (kg)':<25} {m_accepted:<15.3f} {experimental_mass_part1:<15.3f} {mass_error_part1:>15.2f}%\")\n",
    "print(f\"{'Friction (N)':<25} {F_expected:<15.3f} {experimental_friction_part1:<15.3f} {friction_error_part1:>15.2f}%\")\n",
    "\n",
    "print('\\n' + '-' * 60)\n",
    "print('INTERPRETATION:')\n",
    "print('-' * 60)\n",
    "print(f\"‚Ä¢ Mass Error: {mass_error_part1:.2f}% - \", end=\"\")\n",
    "if mass_error_part1 < 5:\n",
    "    print(\"Excellent! Very close to theoretical value.\")\n",
    "elif mass_error_part1 < 10:\n",
    "    print(\"Good! Reasonably close to theoretical value.\")\n",
    "elif mass_error_part1 < 20:\n",
    "    print(\"Moderate. Some discrepancy from theoretical value.\")\n",
    "else:\n",
    "    print(\"Large error. May need data cleaning (see Part 2).\")\n",
    "\n",
    "print(f\"‚Ä¢ Friction Error: {friction_error_part1:.2f}% - \", end=\"\")\n",
    "if friction_error_part1 < 10:\n",
    "    print(\"Good agreement with expected value.\")\n",
    "elif friction_error_part1 < 20:\n",
    "    print(\"Reasonable agreement.\")\n",
    "else:\n",
    "    print(\"Significant difference. May improve with data cleaning.\")\n",
    "\n",
    "print('\\n' + '=' * 60)\n",
    "print('NOTE: In Part 2, we will clean the data and see if we can improve these errors.')\n",
    "print('=' * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5880fe",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Part 1 Summary\n",
    "\n",
    "**Congratulations!** You've successfully:\n",
    "\n",
    "1. ‚úÖ Loaded and visualized experimental data\n",
    "2. ‚úÖ Applied linear regression to find the line of best fit\n",
    "3. ‚úÖ Interpreted the slope (mass) and intercept (friction)\n",
    "4. ‚úÖ Understood R¬≤ as a measure of fit quality\n",
    "5. ‚úÖ Compared experimental results to theoretical values using percent error\n",
    "\n",
    "**Key Takeaway:** Linear regression allows us to extract physical quantities (mass and friction) from experimental data by finding the best-fit line. We can then compare these experimental values to theoretical values to assess the quality of our measurements.\n",
    "\n",
    "**Next:** In Part 2, we'll learn how to improve our results by identifying and removing problematic data points.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d51e76",
   "metadata": {},
   "source": [
    "# üîç PART 2: Improving Our Analysis Through Data Cleaning\n",
    "\n",
    "## Learning Goal: Learn how to identify and remove problematic data points\n",
    "\n",
    "**Remember from Part 1:** We performed linear regression on all data points and found our initial results.\n",
    "\n",
    "**Question:** Can we improve our results by removing problematic data points?\n",
    "\n",
    "In real experiments, some data points might be problematic due to:\n",
    "* Experimental errors (measurement mistakes)\n",
    "* Different physical regimes (like static vs. kinetic friction)\n",
    "* Equipment issues (sticky wheels, etc.)\n",
    "\n",
    "By carefully examining our data and removing problematic points, we can get a better fit and more accurate results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c369c7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ü§î Reflection: Can We Improve Our Results?\n",
    "\n",
    "Look back at our scatter plot from Part 1. Do you notice:\n",
    "\n",
    "* A point at acceleration = 0? (This represents static friction)\n",
    "* Any points that seem far from where a straight line would be?\n",
    "\n",
    "These might be candidates for removal. Let's examine them systematically.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee3de9e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚öñÔ∏è Step 1: Remove the Static Friction Point (a=0)\n",
    "\n",
    "**Physical Justification:** The point at acceleration = 0 represents **static friction**‚Äîthe force needed to *start* the cart moving. Once moving, we deal with **kinetic friction**, which is different.\n",
    "\n",
    "For analyzing Newton's Second Law ($F = ma$), we want to focus on **accelerating** data points. Let's remove the a=0 point and see how it affects our results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94997b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the a=0 point (static friction point) - this is index 0\n",
    "# [Language-A: Python]\n",
    "df_no_static = df.iloc[1:].copy()  # Remove first row (a=0 point)\n",
    "X_no_static = df_no_static['Acceleration']\n",
    "Y_no_static = df_no_static['Force']\n",
    "\n",
    "# Perform linear regression on data without static friction point\n",
    "slope_no_static, intercept_no_static, r_value_no_static, p_value_no_static, std_err_no_static = linregress(X_no_static, Y_no_static)\n",
    "r_squared_no_static = r_value_no_static**2\n",
    "\n",
    "# [Language-B: R]\n",
    "# df_no_static <- slice(df, 2:n())\n",
    "# model_no_static <- lm(Force ~ Acceleration, data=df_no_static)\n",
    "# slope_no_static <- coef(model_no_static)['Acceleration']\n",
    "# intercept_no_static <- coef(model_no_static)['(Intercept)']\n",
    "# r_squared_no_static <- summary(model_no_static)$r.squared\n",
    "# std_err_no_static <- summary(model_no_static)$coefficients['Acceleration', 'Std. Error']\n",
    "\n",
    "# Print results\n",
    "print('=' * 60)\n",
    "print('=' * 60)\n",
    "print('REGRESSION: Data WITHOUT Static Friction Point (a=0)')\n",
    "print('=' * 60)\n",
    "print('=' * 60)\n",
    "print(f\"Mass (Slope): {slope_no_static:.3f} kg\")\n",
    "print(f\"Friction Force (Y-Intercept): {intercept_no_static:.3f} N\")\n",
    "print(f\"R-squared: {r_squared_no_static:.4f} ({r_squared_no_static*100:.1f}% of variation explained)\")\n",
    "print(f\"Standard Error of Mass: {std_err_no_static:.3f} kg\")\n",
    "print(f\"\\nEquation: F = {slope_no_static:.3f}a + {intercept_no_static:.3f}\")\n",
    "\n",
    "# Compare R¬≤ improvement\n",
    "r2_improvement = r_squared_no_static - r_squared_all\n",
    "print(f\"\\n\" + '-' * 60)\n",
    "print('R-SQUARED IMPROVEMENT:')\n",
    "print('-' * 60)\n",
    "print(f\"Baseline (all data):     R¬≤ = {r_squared_all:.4f} ({r_squared_all*100:.1f}%)\")\n",
    "print(f\"Without static friction: R¬≤ = {r_squared_no_static:.4f} ({r_squared_no_static*100:.1f}%)\")\n",
    "print(f\"Change:                  ŒîR¬≤ = {r2_improvement:+.4f} ({r2_improvement*100:+.1f} percentage points)\")\n",
    "\n",
    "if r2_improvement > 0:\n",
    "    print(f\"\\n‚úì Good! Removing the static friction point improved the fit.\")\n",
    "    print(f\"  The line now explains {r2_improvement*100:.1f}% more of the variation in the data.\")\n",
    "elif r2_improvement < 0:\n",
    "    print(f\"\\n‚ö† Unexpected: R¬≤ decreased. This might indicate the a=0 point was actually useful.\")\n",
    "else:\n",
    "    print(f\"\\n‚Üí No change in R¬≤. The a=0 point didn't significantly affect the fit.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e02ba43",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìâ Step 2: Examine Residuals to Find Outliers\n",
    "\n",
    "**Residuals** are the vertical distances between each data point and the regression line. They show us which points don't fit well.\n",
    "\n",
    "By plotting residuals, we can identify potential outliers that might need to be removed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156e9b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals for data without static friction point\n",
    "# Residual = Observed Y - Predicted Y\n",
    "# [Language-A: Python]\n",
    "Y_fit_no_static = slope_no_static * X_no_static + intercept_no_static\n",
    "residuals_no_static = Y_no_static - Y_fit_no_static\n",
    "\n",
    "# [Language-B: R]\n",
    "# Y_fit_no_static <- predict(model_no_static, newdata = data.frame(Acceleration = X_no_static))\n",
    "# residuals_no_static <- residuals(model_no_static)\n",
    "\n",
    "# Calculate statistics for outlier detection\n",
    "residual_mean = np.mean(residuals_no_static)\n",
    "residual_std = np.std(residuals_no_static, ddof=1)  # Sample standard deviation\n",
    "\n",
    "# Create a table showing all data points with their residuals\n",
    "print('=' * 80)\n",
    "print('DATA POINTS WITH RESIDUALS (after removing a=0 point)')\n",
    "print('=' * 80)\n",
    "print(f\"{'Index':<8} {'Acceleration':<15} {'Force':<10} {'Residual':<12} {'|Residual|/œÉ':<15} {'Status'}\")\n",
    "print('-' * 80)\n",
    "\n",
    "# Create a list to store point information for user selection\n",
    "point_info = []\n",
    "for i, idx in enumerate(df_no_static.index):\n",
    "    accel = df_no_static.loc[idx, 'Acceleration']\n",
    "    force = df_no_static.loc[idx, 'Force']\n",
    "    residual = residuals_no_static.iloc[i] if hasattr(residuals_no_static, 'iloc') else residuals_no_static[i]\n",
    "    abs_residual_sigma = abs(residual) / residual_std\n",
    "    \n",
    "    # Determine status\n",
    "    if abs_residual_sigma > 3:\n",
    "        status = \">3œÉ (likely outlier)\"\n",
    "    elif abs_residual_sigma > 2:\n",
    "        status = \">2œÉ (possible outlier)\"\n",
    "    else:\n",
    "        status = \"Normal\"\n",
    "    \n",
    "    point_info.append({\n",
    "        'index': idx,\n",
    "        'accel': accel,\n",
    "        'force': force,\n",
    "        'residual': residual,\n",
    "        'abs_residual_sigma': abs_residual_sigma\n",
    "    })\n",
    "    \n",
    "    print(f\"{idx:<8} {accel:<15.2f} {force:<10.2f} {residual:<12.4f} {abs_residual_sigma:<15.2f} {status}\")\n",
    "\n",
    "print('-' * 80)\n",
    "print(f\"\\nMean Residual: {residual_mean:.4f} N\")\n",
    "print(f\"Standard Deviation (œÉ): {residual_std:.4f} N\")\n",
    "print(f\"\\nGuidelines:\")\n",
    "print(f\"  ‚Ä¢ Points with |Residual|/œÉ > 2 may be outliers\")\n",
    "print(f\"  ‚Ä¢ Points with |Residual|/œÉ > 3 are likely outliers\")\n",
    "print(f\"\\nUse the table above to identify which points you want to remove.\")\n",
    "\n",
    "# Create residual plot with point labels\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot residuals\n",
    "scatter = plt.scatter(X_no_static, residuals_no_static, color='green', s=100, alpha=0.7, label='Residuals', zorder=3)\n",
    "plt.hlines(0, min(X_no_static), max(X_no_static), color='red', linestyle='--', linewidth=2, label='Zero Line', zorder=1)\n",
    "\n",
    "# Add ¬±2œÉ and ¬±3œÉ bands for outlier detection\n",
    "plt.axhspan(-2*residual_std, 2*residual_std, alpha=0.1, color='yellow', label='¬±2œÉ band', zorder=0)\n",
    "plt.axhspan(-3*residual_std, 3*residual_std, alpha=0.05, color='orange', label='¬±3œÉ band', zorder=0)\n",
    "\n",
    "# Label points with their index for easy identification\n",
    "for i, idx in enumerate(df_no_static.index):\n",
    "    accel = X_no_static.iloc[i] if hasattr(X_no_static, 'iloc') else X_no_static[i]\n",
    "    residual = residuals_no_static.iloc[i] if hasattr(residuals_no_static, 'iloc') else residuals_no_static[i]\n",
    "    plt.annotate(f'{idx}', (accel, residual), xytext=(5, 5), textcoords='offset points', \n",
    "                fontsize=8, alpha=0.7)\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Residual Plot: Identifying Outliers (Numbers = Data Point Index)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Acceleration (a in $m/s^2$)', fontsize=12)\n",
    "plt.ylabel('Residual (N)', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8558cd4b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Step 3: Choose Which Points to Remove\n",
    "\n",
    "Based on the residual plot and table above, you can now choose which data points to remove. Look for points with:\n",
    "\n",
    "* Large residuals (far from zero)\n",
    "* |Residual|/œÉ > 2 (statistically significant deviation)\n",
    "\n",
    "Edit the code below to specify which points to remove.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76be8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# USER INPUT: Choose which points to remove\n",
    "# ============================================================================\n",
    "# Option 1: Remove points by INDEX (recommended - use the index numbers from the plot)\n",
    "#           Example: points_to_remove_by_index = [2, 5]  # Remove points with indices 2 and 5\n",
    "#           Example: points_to_remove_by_index = []     # Don't remove any points\n",
    "\n",
    "points_to_remove_by_index = []  # <-- EDIT THIS: List of indices to remove (e.g., [2, 5])\n",
    "\n",
    "# Option 2: Remove points by ACCELERATION VALUE\n",
    "#           Example: points_to_remove_by_accel = [0.23, 0.52]  # Remove points with these acceleration values\n",
    "#           Example: points_to_remove_by_accel = []            # Don't remove any points\n",
    "\n",
    "points_to_remove_by_accel = []  # <-- EDIT THIS: List of acceleration values to remove (e.g., [0.23, 0.52])\n",
    "\n",
    "# Option 3: Automatically remove points using 2œÉ rule (uncomment to use)\n",
    "#           This will automatically remove all points with |Residual|/œÉ > 2\n",
    "# use_auto_2sigma = True  # <-- Uncomment this line to use automatic 2œÉ rule\n",
    "\n",
    "# ============================================================================\n",
    "# Process user selections\n",
    "# ============================================================================\n",
    "\n",
    "# Start with all data points (excluding the a=0 point that was already removed)\n",
    "indices_to_remove = set()\n",
    "\n",
    "# Add indices specified by user\n",
    "if len(points_to_remove_by_index) > 0:\n",
    "    for idx in points_to_remove_by_index:\n",
    "        if idx in df_no_static.index:\n",
    "            indices_to_remove.add(idx)\n",
    "        else:\n",
    "            print(f\"Warning: Index {idx} not found in dataset (already removed or doesn't exist)\")\n",
    "\n",
    "# Add indices based on acceleration values\n",
    "if len(points_to_remove_by_accel) > 0:\n",
    "    for accel_val in points_to_remove_by_accel:\n",
    "        matching = df_no_static[df_no_static['Acceleration'] == accel_val]\n",
    "        if len(matching) > 0:\n",
    "            indices_to_remove.update(matching.index.tolist())\n",
    "        else:\n",
    "            print(f\"Warning: No point found with acceleration = {accel_val} m/s¬≤\")\n",
    "\n",
    "# Option: Use automatic 2œÉ rule (if enabled)\n",
    "try:\n",
    "    if use_auto_2sigma:\n",
    "        outlier_threshold = 2 * residual_std\n",
    "        outlier_mask = np.abs(residuals_no_static) > outlier_threshold\n",
    "        auto_outlier_indices = df_no_static.index[outlier_mask].tolist()\n",
    "        indices_to_remove.update(auto_outlier_indices)\n",
    "        print(f\"Auto-detected {len(auto_outlier_indices)} outlier(s) using 2œÉ rule\")\n",
    "except NameError:\n",
    "    pass  # use_auto_2sigma not defined, skip automatic detection\n",
    "\n",
    "# Convert to list and sort\n",
    "indices_to_remove = sorted(list(indices_to_remove))\n",
    "\n",
    "# Print what will be removed\n",
    "print('=' * 60)\n",
    "print('POINTS SELECTED FOR REMOVAL')\n",
    "print('=' * 60)\n",
    "if len(indices_to_remove) > 0:\n",
    "    print(f\"Removing {len(indices_to_remove)} point(s):\")\n",
    "    for idx in indices_to_remove:\n",
    "        accel = df_no_static.loc[idx, 'Acceleration']\n",
    "        force = df_no_static.loc[idx, 'Force']\n",
    "        # Find residual for this point\n",
    "        residual_idx = df_no_static.index.get_loc(idx)\n",
    "        residual = residuals_no_static.iloc[residual_idx] if hasattr(residuals_no_static, 'iloc') else residuals_no_static[residual_idx]\n",
    "        abs_residual_sigma = abs(residual) / residual_std\n",
    "        print(f\"  Index {idx}: a={accel:.2f} m/s¬≤, F={force:.2f} N, |Residual|/œÉ={abs_residual_sigma:.2f}\")\n",
    "else:\n",
    "    print(\"No points selected for removal - using all data points (except a=0)\")\n",
    "\n",
    "# Create clean dataset\n",
    "if len(indices_to_remove) > 0:\n",
    "    df_clean = df_no_static[~df_no_static.index.isin(indices_to_remove)].copy()\n",
    "else:\n",
    "    df_clean = df_no_static.copy()\n",
    "\n",
    "X_clean = df_clean['Acceleration']\n",
    "Y_clean = df_clean['Force']\n",
    "\n",
    "print(f\"\\nClean dataset: {len(df_clean)} points (removed {len(indices_to_remove)} point(s))\")\n",
    "\n",
    "# Perform FINAL regression on clean data\n",
    "slope_clean, intercept_clean, r_value_clean, p_value_clean, std_err_clean = linregress(X_clean, Y_clean)\n",
    "r_squared_clean = r_value_clean**2\n",
    "\n",
    "# [Language-B: R]\n",
    "# df_clean <- df_no_static[!df_no_static$index %in% indices_to_remove, ]\n",
    "# model_clean <- lm(Force ~ Acceleration, data=df_clean)\n",
    "# slope_clean <- coef(model_clean)['Acceleration']\n",
    "# intercept_clean <- coef(model_clean)['(Intercept)']\n",
    "# r_squared_clean <- summary(model_clean)$r.squared\n",
    "# std_err_clean <- summary(model_clean)$coefficients['Acceleration', 'Std. Error']\n",
    "\n",
    "# Store outlier_indices for use in visualization (convert to list for compatibility)\n",
    "outlier_indices = indices_to_remove\n",
    "\n",
    "# Print final results\n",
    "print('\\n' + '=' * 60)\n",
    "print('FINAL REGRESSION: CLEAN DATA')\n",
    "print('=' * 60)\n",
    "print(f\"Mass (Slope): {slope_clean:.3f} kg\")\n",
    "print(f\"Friction Force (Y-Intercept): {intercept_clean:.3f} N\")\n",
    "print(f\"R-squared: {r_squared_clean:.4f} ({r_squared_clean*100:.1f}% of variation explained)\")\n",
    "print(f\"Standard Error of Mass: {std_err_clean:.3f} kg\")\n",
    "print(f\"\\nFinal Equation: F = {slope_clean:.3f}a + {intercept_clean:.3f}\")\n",
    "\n",
    "# Interpret final R¬≤\n",
    "print('\\n' + '-' * 60)\n",
    "print('FINAL R-SQUARED INTERPRETATION:')\n",
    "print('-' * 60)\n",
    "if r_squared_clean >= 0.95:\n",
    "    interpretation = \"Excellent fit! Our cleaned data shows a very strong linear relationship.\"\n",
    "elif r_squared_clean >= 0.80:\n",
    "    interpretation = \"Good fit. The linear relationship is strong, with some expected experimental scatter.\"\n",
    "elif r_squared_clean >= 0.50:\n",
    "    interpretation = \"Moderate fit. There's a linear trend, but significant scatter remains.\"\n",
    "else:\n",
    "    interpretation = \"Poor fit. The linear relationship is weak‚Äîconsider investigating experimental errors.\"\n",
    "\n",
    "print(f\"R¬≤ = {r_squared_clean:.4f} means: {interpretation}\")\n",
    "print(f\"\\nThis is our best estimate of the true relationship between Force and Acceleration.\")\n",
    "\n",
    "# Compare all three regressions\n",
    "print('\\n' + '=' * 60)\n",
    "print('\\n' + '=' * 60)\n",
    "print('COMPARISON: Part 1 vs Part 2 (Final Clean Data)')\n",
    "print('=' * 60)\n",
    "print(f\"{'Metric':<25} {'Part 1 (All Data)':<20} {'Part 2 (Clean Data)':<20} {'Improvement'}\")\n",
    "print('-' * 60)\n",
    "print(f\"{'R-squared':<25} {r_squared_all:<20.4f} {r_squared_clean:<20.4f} {r_squared_clean-r_squared_all:+.4f}\")\n",
    "print(f\"{'R¬≤ (% explained)':<25} {r_squared_all*100:<20.1f}% {r_squared_clean*100:<20.1f}% {r_squared_clean*100-r_squared_all*100:+.1f}%\")\n",
    "print(f\"{'Mass (kg)':<25} {slope_all:<20.3f} {slope_clean:<20.3f} {slope_clean-slope_all:+.3f}\")\n",
    "print(f\"{'Friction (N)':<25} {intercept_all:<20.3f} {intercept_clean:<20.3f} {intercept_clean-intercept_all:+.3f}\")\n",
    "print(f\"{'Metric':<25} {'Baseline':<12} {'No Static':<12} {'Clean Data':<12} {'Change'}\")\n",
    "print('-' * 60)\n",
    "print(f\"{'R-squared':<25} {r_squared_all:<12.4f} {r_squared_no_static:<12.4f} {r_squared_clean:<12.4f} {r_squared_clean-r_squared_all:+.4f}\")\n",
    "print(f\"{'R¬≤ (% explained)':<25} {r_squared_all*100:<12.1f}% {r_squared_no_static*100:<12.1f}% {r_squared_clean*100:<12.1f}% {r_squared_clean*100-r_squared_all*100:+.1f}%\")\n",
    "print(f\"{'Mass (kg)':<25} {slope_all:<12.3f} {slope_no_static:<12.3f} {slope_clean:<12.3f} {slope_clean-slope_all:+.3f}\")\n",
    "print(f\"{'Friction (N)':<25} {intercept_all:<12.3f} {intercept_no_static:<12.3f} {intercept_clean:<12.3f} {intercept_clean-intercept_all:+.3f}\")\n",
    "\n",
    "print('\\n' + '-' * 60)\n",
    "print('\\n' + '-' * 60)\n",
    "print('KEY INSIGHT:')\n",
    "print('-' * 60)\n",
    "total_improvement = r_squared_clean - r_squared_all\n",
    "print(f'By cleaning the data, we improved R¬≤ by {total_improvement:.4f} ({total_improvement*100:.1f} percentage points).')\n",
    "print(f'This means our final model explains {total_improvement*100:.1f}% more of the variation than Part 1.')\n",
    "print(f'Data cleaning successfully improved our analysis!')\n",
    "total_improvement = r_squared_clean - r_squared_all\n",
    "print(f\"By cleaning the data, we improved R¬≤ by {total_improvement:.4f} ({total_improvement*100:.1f} percentage points).\")\n",
    "print(f\"This means our final model explains {total_improvement*100:.1f}% more of the variation than the baseline.\")\n",
    "print(f\"The data cleaning process successfully removed problematic points and improved our analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d843bc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Step 4: Compare Results\n",
    "\n",
    "Let's see how our cleaned data compares to our original analysis from Part 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04c4116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# USER INPUT: Choose which points to remove\n",
    "# ============================================================================\n",
    "# Option 1: Remove points by INDEX (recommended - use the index numbers from the plot)\n",
    "#           Example: points_to_remove_by_index = [2, 5]  # Remove points with indices 2 and 5\n",
    "#           Example: points_to_remove_by_index = []     # Don't remove any points\n",
    "\n",
    "points_to_remove_by_index = []  # <-- EDIT THIS: List of indices to remove (e.g., [2, 5])\n",
    "\n",
    "# Option 2: Remove points by ACCELERATION VALUE\n",
    "#           Example: points_to_remove_by_accel = [0.23, 0.52]  # Remove points with these acceleration values\n",
    "#           Example: points_to_remove_by_accel = []            # Don't remove any points\n",
    "\n",
    "points_to_remove_by_accel = []  # <-- EDIT THIS: List of acceleration values to remove (e.g., [0.23, 0.52])\n",
    "\n",
    "# Option 3: Automatically remove points using 2œÉ rule (uncomment to use)\n",
    "#           This will automatically remove all points with |Residual|/œÉ > 2\n",
    "# use_auto_2sigma = True  # <-- Uncomment this line to use automatic 2œÉ rule\n",
    "\n",
    "# ============================================================================\n",
    "# Process user selections\n",
    "# ============================================================================\n",
    "\n",
    "# Start with all data points (excluding the a=0 point that was already removed)\n",
    "indices_to_remove = set()\n",
    "\n",
    "# Add indices specified by user\n",
    "if len(points_to_remove_by_index) > 0:\n",
    "    for idx in points_to_remove_by_index:\n",
    "        if idx in df_no_static.index:\n",
    "            indices_to_remove.add(idx)\n",
    "        else:\n",
    "            print(f\"Warning: Index {idx} not found in dataset (already removed or doesn't exist)\")\n",
    "\n",
    "# Add indices based on acceleration values\n",
    "if len(points_to_remove_by_accel) > 0:\n",
    "    for accel_val in points_to_remove_by_accel:\n",
    "        matching = df_no_static[df_no_static['Acceleration'] == accel_val]\n",
    "        if len(matching) > 0:\n",
    "            indices_to_remove.update(matching.index.tolist())\n",
    "        else:\n",
    "            print(f\"Warning: No point found with acceleration = {accel_val} m/s¬≤\")\n",
    "\n",
    "# Option: Use automatic 2œÉ rule (if enabled)\n",
    "try:\n",
    "    if use_auto_2sigma:\n",
    "        outlier_threshold = 2 * residual_std\n",
    "        outlier_mask = np.abs(residuals_no_static) > outlier_threshold\n",
    "        auto_outlier_indices = df_no_static.index[outlier_mask].tolist()\n",
    "        indices_to_remove.update(auto_outlier_indices)\n",
    "        print(f\"Auto-detected {len(auto_outlier_indices)} outlier(s) using 2œÉ rule\")\n",
    "except NameError:\n",
    "    pass  # use_auto_2sigma not defined, skip automatic detection\n",
    "\n",
    "# Convert to list and sort\n",
    "indices_to_remove = sorted(list(indices_to_remove))\n",
    "\n",
    "# Print what will be removed\n",
    "print('=' * 60)\n",
    "print('POINTS SELECTED FOR REMOVAL')\n",
    "print('=' * 60)\n",
    "if len(indices_to_remove) > 0:\n",
    "    print(f\"Removing {len(indices_to_remove)} point(s):\")\n",
    "    for idx in indices_to_remove:\n",
    "        accel = df_no_static.loc[idx, 'Acceleration']\n",
    "        force = df_no_static.loc[idx, 'Force']\n",
    "        # Find residual for this point\n",
    "        residual_idx = df_no_static.index.get_loc(idx)\n",
    "        residual = residuals_no_static.iloc[residual_idx] if hasattr(residuals_no_static, 'iloc') else residuals_no_static[residual_idx]\n",
    "        abs_residual_sigma = abs(residual) / residual_std\n",
    "        print(f\"  Index {idx}: a={accel:.2f} m/s¬≤, F={force:.2f} N, |Residual|/œÉ={abs_residual_sigma:.2f}\")\n",
    "else:\n",
    "    print(\"No points selected for removal - using all data points (except a=0)\")\n",
    "\n",
    "# Create clean dataset\n",
    "if len(indices_to_remove) > 0:\n",
    "    df_clean = df_no_static[~df_no_static.index.isin(indices_to_remove)].copy()\n",
    "else:\n",
    "    df_clean = df_no_static.copy()\n",
    "\n",
    "X_clean = df_clean['Acceleration']\n",
    "Y_clean = df_clean['Force']\n",
    "\n",
    "print(f\"\\nClean dataset: {len(df_clean)} points (removed {len(indices_to_remove)} point(s))\")\n",
    "\n",
    "# Perform FINAL regression on clean data\n",
    "slope_clean, intercept_clean, r_value_clean, p_value_clean, std_err_clean = linregress(X_clean, Y_clean)\n",
    "r_squared_clean = r_value_clean**2\n",
    "\n",
    "# [Language-B: R]\n",
    "# df_clean <- df_no_static[!df_no_static$index %in% indices_to_remove, ]\n",
    "# model_clean <- lm(Force ~ Acceleration, data=df_clean)\n",
    "# slope_clean <- coef(model_clean)['Acceleration']\n",
    "# intercept_clean <- coef(model_clean)['(Intercept)']\n",
    "# r_squared_clean <- summary(model_clean)$r.squared\n",
    "# std_err_clean <- summary(model_clean)$coefficients['Acceleration', 'Std. Error']\n",
    "\n",
    "# Store outlier_indices for use in visualization (convert to list for compatibility)\n",
    "outlier_indices = indices_to_remove\n",
    "\n",
    "# Print final results\n",
    "print('\\n' + '=' * 60)\n",
    "print('FINAL REGRESSION: CLEAN DATA')\n",
    "print('=' * 60)\n",
    "print(f\"Mass (Slope): {slope_clean:.3f} kg\")\n",
    "print(f\"Friction Force (Y-Intercept): {intercept_clean:.3f} N\")\n",
    "print(f\"R-squared: {r_squared_clean:.4f} ({r_squared_clean*100:.1f}% of variation explained)\")\n",
    "print(f\"Standard Error of Mass: {std_err_clean:.3f} kg\")\n",
    "print(f\"\\nFinal Equation: F = {slope_clean:.3f}a + {intercept_clean:.3f}\")\n",
    "\n",
    "# Interpret final R¬≤\n",
    "print('\\n' + '-' * 60)\n",
    "print('FINAL R-SQUARED INTERPRETATION:')\n",
    "print('-' * 60)\n",
    "if r_squared_clean >= 0.95:\n",
    "    interpretation = \"Excellent fit! Our cleaned data shows a very strong linear relationship.\"\n",
    "elif r_squared_clean >= 0.80:\n",
    "    interpretation = \"Good fit. The linear relationship is strong, with some expected experimental scatter.\"\n",
    "elif r_squared_clean >= 0.50:\n",
    "    interpretation = \"Moderate fit. There's a linear trend, but significant scatter remains.\"\n",
    "else:\n",
    "    interpretation = \"Poor fit. The linear relationship is weak‚Äîconsider investigating experimental errors.\"\n",
    "\n",
    "print(f\"R¬≤ = {r_squared_clean:.4f} means: {interpretation}\")\n",
    "print(f\"\\nThis is our best estimate of the true relationship between Force and Acceleration.\")\n",
    "\n",
    "# Compare all three regressions\n",
    "print('\\n' + '=' * 60)\n",
    "print('\\n' + '=' * 60)\n",
    "print('COMPARISON: Part 1 vs Part 2 (Final Clean Data)')\n",
    "print('=' * 60)\n",
    "print(f\"{'Metric':<25} {'Part 1 (All Data)':<20} {'Part 2 (Clean Data)':<20} {'Improvement'}\")\n",
    "print('-' * 60)\n",
    "print(f\"{'R-squared':<25} {r_squared_all:<20.4f} {r_squared_clean:<20.4f} {r_squared_clean-r_squared_all:+.4f}\")\n",
    "print(f\"{'R¬≤ (% explained)':<25} {r_squared_all*100:<20.1f}% {r_squared_clean*100:<20.1f}% {r_squared_clean*100-r_squared_all*100:+.1f}%\")\n",
    "print(f\"{'Mass (kg)':<25} {slope_all:<20.3f} {slope_clean:<20.3f} {slope_clean-slope_all:+.3f}\")\n",
    "print(f\"{'Friction (N)':<25} {intercept_all:<20.3f} {intercept_clean:<20.3f} {intercept_clean-intercept_all:+.3f}\")\n",
    "print(f\"{'Metric':<25} {'Baseline':<12} {'No Static':<12} {'Clean Data':<12} {'Change'}\")\n",
    "print('-' * 60)\n",
    "print(f\"{'R-squared':<25} {r_squared_all:<12.4f} {r_squared_no_static:<12.4f} {r_squared_clean:<12.4f} {r_squared_clean-r_squared_all:+.4f}\")\n",
    "print(f\"{'R¬≤ (% explained)':<25} {r_squared_all*100:<12.1f}% {r_squared_no_static*100:<12.1f}% {r_squared_clean*100:<12.1f}% {r_squared_clean*100-r_squared_all*100:+.1f}%\")\n",
    "print(f\"{'Mass (kg)':<25} {slope_all:<12.3f} {slope_no_static:<12.3f} {slope_clean:<12.3f} {slope_clean-slope_all:+.3f}\")\n",
    "print(f\"{'Friction (N)':<25} {intercept_all:<12.3f} {intercept_no_static:<12.3f} {intercept_clean:<12.3f} {intercept_clean-intercept_all:+.3f}\")\n",
    "\n",
    "print('\\n' + '-' * 60)\n",
    "print('\\n' + '-' * 60)\n",
    "print('KEY INSIGHT:')\n",
    "print('-' * 60)\n",
    "total_improvement = r_squared_clean - r_squared_all\n",
    "print(f'By cleaning the data, we improved R¬≤ by {total_improvement:.4f} ({total_improvement*100:.1f} percentage points).')\n",
    "print(f'This means our final model explains {total_improvement*100:.1f}% more of the variation than Part 1.')\n",
    "print(f'Data cleaning successfully improved our analysis!')\n",
    "total_improvement = r_squared_clean - r_squared_all\n",
    "print(f\"By cleaning the data, we improved R¬≤ by {total_improvement:.4f} ({total_improvement*100:.1f} percentage points).\")\n",
    "print(f\"This means our final model explains {total_improvement*100:.1f}% more of the variation than the baseline.\")\n",
    "print(f\"The data cleaning process successfully removed problematic points and improved our analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b2c645",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìà Final Visualization\n",
    "\n",
    "Let's create a comprehensive plot showing all data, removed points, and our final best-fit line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ade5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization showing the data cleaning process\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot all original data (gray, small)\n",
    "plt.scatter(df['Acceleration'], df['Force'], color='lightgray', s=50, alpha=0.5, label='All Original Data', zorder=1)\n",
    "\n",
    "# Highlight the a=0 point that was removed (static friction)\n",
    "plt.scatter(df.iloc[0]['Acceleration'], df.iloc[0]['Force'], \n",
    "           color='orange', s=200, marker='x', linewidths=3, label='Removed: Static Friction (a=0)', zorder=3)\n",
    "\n",
    "# Highlight any middle outliers that were removed\n",
    "if len(outlier_indices) > 0:\n",
    "    for idx in outlier_indices:\n",
    "        plt.scatter(df_no_static.loc[idx, 'Acceleration'], df_no_static.loc[idx, 'Force'],\n",
    "                   color='red', s=200, marker='x', linewidths=3, zorder=3)\n",
    "    if len(outlier_indices) == 1:\n",
    "        plt.scatter([], [], color='red', s=200, marker='x', linewidths=3, label='Removed: Outlier (2œÉ rule)')\n",
    "\n",
    "# Plot clean data used in final regression (blue, large)\n",
    "plt.scatter(X_clean, Y_clean, color='darkblue', s=150, alpha=0.8, \n",
    "           label=f'Clean Data (n={len(df_clean)})', zorder=2, edgecolors='black', linewidths=1)\n",
    "\n",
    "# Plot final best-fit line\n",
    "Y_fit_clean = slope_clean * X_clean + intercept_clean\n",
    "plt.plot(X_clean, Y_fit_clean, color='red', linestyle='-', linewidth=2.5, \n",
    "         label=f'Final Best Fit (R¬≤ = {r_squared_clean:.4f})', zorder=2)\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Final Analysis: Clean Data with Best Fit Line', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Acceleration (a in $m/s^2$)', fontsize=12)\n",
    "plt.ylabel('Applied Force (F in N)', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend(loc='lower right', fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nFinal Analysis Summary:')\n",
    "print(f'  ‚Ä¢ Started with {len(df)} data points')\n",
    "print(f'  ‚Ä¢ Removed 1 static friction point (a=0)')\n",
    "if len(outlier_indices) > 0:\n",
    "    print(f'  ‚Ä¢ Removed {len(outlier_indices)} outlier(s) using 2œÉ rule')\n",
    "print(f'  ‚Ä¢ Final clean dataset: {len(df_clean)} points')\n",
    "print(f'  ‚Ä¢ Final R¬≤: {r_squared_clean:.4f}')\n",
    "print(f'  ‚Ä¢ Final Mass: {slope_clean:.3f} kg')\n",
    "print(f'  ‚Ä¢ Final Friction: {intercept_clean:.3f} N')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741fdefc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Part 2 Summary\n",
    "\n",
    "**Great work!** You've learned how to:\n",
    "\n",
    "1. ‚úÖ Identify problematic data points (static friction, outliers)\n",
    "2. ‚úÖ Use residuals to find statistical outliers\n",
    "3. ‚úÖ Make informed decisions about data cleaning\n",
    "4. ‚úÖ See how data cleaning improves R¬≤ and accuracy\n",
    "\n",
    "**Key Takeaway:** Careful data analysis and cleaning can significantly improve the quality of your results. This is an essential skill in scientific data analysis!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cd7e8b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîç Comparing Final Results to Theoretical Values\n",
    "\n",
    "Now let's compare our **final cleaned data results** from Part 2 to the theoretical values we defined at the beginning.\n",
    "\n",
    "**Percent Error** tells us how far off our experimental value is from the accepted value:\n",
    "\n",
    "$$\\text{Percent Error} = \\left| \\frac{\\text{Experimental Value} - \\text{Accepted Value}}{\\text{Accepted Value}} \\right| \\times 100\\%$$\n",
    "\n",
    "We'll compare both mass and friction to see how well our cleaned data matches the theoretical values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12a8e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare final clean data results to theoretical values\n",
    "# Use the theoretical values defined earlier: m_accepted and F_expected\n",
    "\n",
    "# Experimental values from final clean data regression\n",
    "experimental_mass_final = slope_clean  # Mass from slope\n",
    "experimental_friction_final = intercept_clean  # Friction from intercept\n",
    "\n",
    "# Calculate percent errors for final clean data\n",
    "mass_error_final = abs((experimental_mass_final - m_accepted) / m_accepted) * 100\n",
    "friction_error_final = abs((experimental_friction_final - F_expected) / F_expected) * 100\n",
    "\n",
    "# Also calculate errors for Part 1 and intermediate steps for comparison\n",
    "mass_error_part1 = abs((slope_all - m_accepted) / m_accepted) * 100\n",
    "mass_error_no_static = abs((slope_no_static - m_accepted) / m_accepted) * 100\n",
    "\n",
    "print('=' * 60)\n",
    "print('PART 2: FINAL CLEAN DATA vs THEORETICAL VALUES')\n",
    "print('=' * 60)\n",
    "print(f\"\\n{'Quantity':<25} {'Theoretical':<15} {'Experimental':<15} {'Percent Error'}\")\n",
    "print('-' * 60)\n",
    "print(f\"{'Mass (kg)':<25} {m_accepted:<15.3f} {experimental_mass_final:<15.3f} {mass_error_final:>15.2f}%\")\n",
    "print(f\"{'Friction (N)':<25} {F_expected:<15.3f} {experimental_friction_final:<15.3f} {friction_error_final:>15.2f}%\")\n",
    "\n",
    "print('\\n' + '-' * 60)\n",
    "print('INTERPRETATION:')\n",
    "print('-' * 60)\n",
    "print(f\"‚Ä¢ Mass Error: {mass_error_final:.2f}% - \", end=\"\")\n",
    "if mass_error_final < 5:\n",
    "    print(\"Excellent! Very close to theoretical value.\")\n",
    "elif mass_error_final < 10:\n",
    "    print(\"Good! Reasonably close to theoretical value.\")\n",
    "elif mass_error_final < 20:\n",
    "    print(\"Moderate. Some discrepancy from theoretical value.\")\n",
    "else:\n",
    "    print(\"Large error. May need further investigation.\")\n",
    "\n",
    "print(f\"‚Ä¢ Friction Error: {friction_error_final:.2f}% - \", end=\"\")\n",
    "if friction_error_final < 10:\n",
    "    print(\"Good agreement with expected value.\")\n",
    "elif friction_error_final < 20:\n",
    "    print(\"Reasonable agreement.\")\n",
    "else:\n",
    "    print(\"Significant difference.\")\n",
    "\n",
    "# Compare improvement from Part 1 to Part 2\n",
    "print('\\n' + '=' * 60)\n",
    "print('IMPROVEMENT: Part 1 ‚Üí Part 2')\n",
    "print('=' * 60)\n",
    "print(f\"{'Metric':<25} {'Part 1 Error':<15} {'Part 2 Error':<15} {'Improvement'}\")\n",
    "print('-' * 60)\n",
    "mass_improvement = mass_error_part1 - mass_error_final\n",
    "print(f\"{'Mass Error (%)':<25} {mass_error_part1:<15.2f}% {mass_error_final:<15.2f}% {mass_improvement:>15.2f}%\")\n",
    "\n",
    "if mass_improvement > 0:\n",
    "    print(f\"\\n‚úì Success! Data cleaning reduced mass error by {mass_improvement:.2f} percentage points.\")\n",
    "elif mass_improvement < 0:\n",
    "    print(f\"\\n‚ö† Note: Mass error increased by {abs(mass_improvement):.2f} percentage points.\")\n",
    "    print(\"   This might indicate that some removed points were actually valid.\")\n",
    "else:\n",
    "    print(f\"\\n‚Üí No change in mass error.\")\n",
    "\n",
    "print('=' * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d445db34",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö PLANNED USE: Integrating into Middle/High School Curriculum\n",
    "\n",
    "This notebook covers three main learning goals, making it highly adaptable:\n",
    "\n",
    "* **Statistical Goal:** Understanding **linear regression** (slope, y-intercept), **model fit** ($R^2$), and **quantifying uncertainty** (error analysis, residuals).\n",
    "\n",
    "* **Code Goal:** **Loading data**, **generating scatter plots**, and using functions to **perform calculations** and **visualize results**.\n",
    "\n",
    "* **Content Goal:** Applying **Newton's Second Law** and understanding how real-world effects (friction) modify theoretical models.\n",
    "\n",
    "### Integration Ideas:\n",
    "\n",
    "* **9th Grade Physics/Physical Science:** Students complete the experiment, plot the raw data in a notebook, and use the regression to find their *own* measured mass and compare it to the known mass of the cart.\n",
    "\n",
    "* **11th Grade Algebra II/Pre-Calculus:** Students can focus on the regression mathematics, using different data sets to practice identifying independent/dependent variables and interpreting the meaning of the slope and intercept in different contexts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda1c3d7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ú® CONTENT EXTENSIONS: Beyond $\\mathbf{F}=m\\mathbf{a}$\n",
    "\n",
    "The computational skills and regression logic used here can be applied to many other linear laws in science and mathematics:\n",
    "\n",
    "* **Hooke's Law (Springs):** Plotting Force (F) vs. Displacement (x) to find the **Spring Constant (k)**, since $\\mathbf{F} = k \\cdot \\mathbf{x}$. The slope is $k$.\n",
    "\n",
    "* **Ohm's Law (Circuits):** Plotting Voltage (V) vs. Current (I) to find the **Resistance (R)**, since $\\mathbf{V} = \\mathbf{I} \\cdot \\mathbf{R}$. The slope is $R$.\n",
    "\n",
    "* **Growth Models (Biology/Finance):** Using linear regression on **Time-Series Data** (e.g., population growth vs. time or stock price vs. time) to find the **linear rate of growth** (the slope)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4613bd8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üí° DISPOSITIONS: Developing a Productive Mindset\n",
    "\n",
    "As you explore computational notebooks, remember these key ideas:\n",
    "\n",
    "* **It's Okay to Be Uncertain:** Coding and data analysis involve trial and error. If a cell produces an error, read the message and try to fix it. This is how scientists and programmers work!\n",
    "\n",
    "* **Modify and Test:** The best way to learn is to change the code. For example, change the color of the scatter plot, or change the `accepted_mass` in the final cell and re-run. Test your understanding!\n",
    "\n",
    "* **Document Your Thinking:** Use the Markdown cells (like this one!) to write down your observations and conclusions. This practice helps both you and anyone else who reviews your work."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}